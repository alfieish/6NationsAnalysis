{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline:**\n",
    "\n",
    "The Purpose of this notebook is to scrape the ESPN website for international rubgby player statistics. The script could easily be adapted for other sports and for stats about the games themselves but I've not tested that as all I want at this point in time are stats for players featuring in the 6 nations championship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time, bs4, requests\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotVisibleException\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below numbers show the 6 nations teams as identified in the ESPN system.\n",
    "\n",
    "Finding other teams should be as simple as going to their main page and checking the address bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "england = \"1\"\n",
    "scotland = \"2\"\n",
    "ireland = \"3\"\n",
    "wales = \"4\"\n",
    "france = \"9\"\n",
    "italy = \"20\"\n",
    "lions = \"32\" #2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we go to the page summarising all the games that a team has played in a given year. \n",
    "\n",
    "We use a webdriver and Beautiful Soup to strip this table to provide us with the date of the match, teams that played, the score and a link to the report on the game where we can find more detailed stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['20151011', 'ROM', 'ITALY', '22 - 32'], 'gameId=182008&league=164205'),\n",
      " (['20151004', 'IRE', 'ITALY', '16 - 9'], 'gameId=181996&league=164205'),\n",
      " (['20150926', 'ITALY', 'CAN', '23 - 18'], 'gameId=181984&league=164205'),\n",
      " (['20150919', 'FRA', 'ITALY', '32 - 10'], 'gameId=181972&league=164205'),\n",
      " (['20150905', 'WALES', 'ITALY', '23 - 19'], 'gameId=252323&league=252321'),\n",
      " (['20150829', 'SCOT', 'ITALY', '48 - 7'], 'gameId=263333&league=252321'),\n",
      " (['20150823', 'ITALY', 'SCOT', '12 - 16'], 'gameId=263325&league=248937'),\n",
      " (['20150321', 'ITALY', 'WALES', '20 - 61'], 'gameId=180691&league=180659'),\n",
      " (['20150315', 'ITALY', 'FRA', '0 - 29'], 'gameId=180690&league=180659'),\n",
      " (['20150228', 'SCOT', 'ITALY', '19 - 22'], 'gameId=180685&league=180659'),\n",
      " (['20150214', 'ENG', 'ITALY', '47 - 17'], 'gameId=180682&league=180659'),\n",
      " (['20150207', 'ITALY', 'IRE', '3 - 26'], 'gameId=180680&league=180659')]\n"
     ]
    }
   ],
   "source": [
    "# Set your team\n",
    "teamNo = \"20\"\n",
    "year = \"2015\"\n",
    "\n",
    "teamSeason =\"http://www.espn.co.uk/rugby/results/_/team/\"+teamNo+\"/season/\"+year\n",
    "\n",
    "browser = webdriver.Chrome(r\"C:\\Users\\Maurice\\Desktop\\Python\\chromedriver_win32\\chromedriver.exe\")\n",
    "browser.get(teamSeason)\n",
    "seasonHTML = browser.page_source\n",
    "browser.close()\n",
    "\n",
    "# Use beautiful soup to search the HTML for the main table containing the results\n",
    "seasonSoup = bs4.BeautifulSoup(seasonHTML, \"html.parser\")\n",
    "schedule = seasonSoup.find(\"div\", {\"id\": \"sched-container\"})\n",
    "tables = schedule.select('table')\n",
    "\n",
    "# Function takes a table and converts it into an array of data.\n",
    "def makeList(table):\n",
    "    result = []\n",
    "    allrows = table.findAll('tr')\n",
    "    for row in allrows:\n",
    "        result.append([])\n",
    "        allcols = row.findAll('td')\n",
    "        for col in allcols:\n",
    "          thestrings = [s for s in col.findAll(text=True)]\n",
    "          thetext = ''.join(thestrings)\n",
    "          result[-1].append(thestrings)\n",
    "    return result\n",
    "\n",
    "# We use the above function in the one below to organise the stats by team\n",
    "# Function returns a list with two sublists\n",
    "def teamFixtures(tableSet):\n",
    "    teams = []\n",
    "    for t in tableSet:\n",
    "        teams.append(makeList(t)[1:])\n",
    "    teams = [i for sublist in teams for i in sublist]\n",
    "    return teams \n",
    "\n",
    "# Applying the function to our table from the results page\n",
    "arrays= teamFixtures(tables)\n",
    "\n",
    "# Below function creates a date format that is useable in a Pandas dataframe \n",
    "monthDict = {\"Feb\":\"02\", \"Mar\":\"03\", \"May\":\"05\", \"Jun\":\"06\", \"Jul\":\"07\", \"Aug\":\"08\", \"Sep\":\"09\", \"Oct\":\"10\", \"Nov\":\"11\", \"Dec\":\"12\"}\n",
    "def dateToNum(date):\n",
    "    monDay = date.split(\", \")[1]\n",
    "    mon, day = monDay.split(\" \")\n",
    "    if len(day) == 1:\n",
    "        day = \"0\"+day\n",
    "    return year+monthDict[mon]+day\n",
    "\n",
    "#We don't want all the information from the arrays table just the date, teams and score\n",
    "namesScore = []\n",
    "for m in arrays:\n",
    "    namesScore.append([dateToNum(m[0][0]), m[1][1], m[2][1], m[1][2]])\n",
    "\n",
    "#We also search through the table for links to the more detailed Full Time report\n",
    "links = []\n",
    "for link in schedule.findAll('a', href=True, text='FT'):\n",
    "    links.append(link['href'])\n",
    "\n",
    "# Some games only have a brief summary and no stats so we'll ditch those from our final list.\n",
    "# The below segment copies the indices of good links to filter our links and data arrays below.\n",
    "duds = []\n",
    "goodLinks = []\n",
    "for i, t in enumerate(links):\n",
    "    if 'report' not in t:\n",
    "        duds.append(i)\n",
    "    else:\n",
    "        goodLinks.append(i)\n",
    "\n",
    "# We're not going to follow the link to the full report. We just want the last segment which identifies the game.\n",
    "links = [i.split(\"?\")[1] for i in links]\n",
    "        \n",
    "full_reports = [list(zip(namesScore,links))[i] for i in goodLinks]\n",
    "pprint(full_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testGame = full_reports[1]\n",
    "testPage = \"http://www.espn.co.uk/rugby/playerstats?\"+testGame[1]\n",
    "\n",
    "browser = webdriver.Chrome(r\"C:\\Users\\Maurice\\Desktop\\Python\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "tabs = [\"Scoring\", \"Attacking\", \"Defending\", \"Discipline\"]\n",
    "\n",
    "#Function goes to an ESPN page of player stats for a game and cycles through four tabs of stats. \n",
    "#It returns a full page of HTML for each\n",
    "def scrapePage(address):\n",
    "    while True:\n",
    "        browser.get(address)\n",
    "        try:\n",
    "            browser.find_element_by_xpath(\"//*[contains(text(),'Yes')]\").click()\n",
    "        except ElementNotVisibleException:\n",
    "            pass\n",
    "        pages = []\n",
    "        count = 0\n",
    "        while count < 4:\n",
    "            try:\n",
    "                browser.find_element_by_xpath(\"//*[contains(text(),'\"+tabs[count]+\"')]\").click() \n",
    "                pages.append(browser.page_source)\n",
    "                count+=1\n",
    "            except NoSuchElementException:\n",
    "                break\n",
    "        if count > 0:\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    browser.close()\n",
    "    return pages\n",
    "\n",
    "#pageSet = scrapePage(testPage)\n",
    "#print(len(pageSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function takes the HTML of a set of pages and returns the first two tables on each.\n",
    "# We already know these are the player stats.\n",
    "def gettables(sources):\n",
    "    output=[]\n",
    "    for s in sources:\n",
    "        soup = bs4.BeautifulSoup(s, \"html.parser\")\n",
    "        tables = soup.select('table')\n",
    "        output.append(tables[0:2])\n",
    "    return output\n",
    "\n",
    "#tables = gettables(pageSet)\n",
    "\n",
    "# Function takes a table and converts it into an array of data.\n",
    "def makeList(table):\n",
    "    result = []\n",
    "    allrows = table.findAll('tr')\n",
    "    for row in allrows:\n",
    "        result.append([])\n",
    "        allcols = row.findAll('td')\n",
    "        for col in allcols:\n",
    "          thestrings = [s for s in col.findAll(text=True)]\n",
    "          thetext = ''.join(thestrings)\n",
    "          result[-1].append(thestrings)\n",
    "    return result\n",
    "\n",
    "# We use the above function in the one below to organise the stats by team\n",
    "# Function returns a list with two sublists\n",
    "def teamTables(tableSet):\n",
    "    team1 = []\n",
    "    team2 = []\n",
    "    for t in tableSet:\n",
    "        team1.append(makeList(t[0]))\n",
    "        team2.append(makeList(t[1]))\n",
    "    teams = [team1,  team2]\n",
    "    return teams \n",
    "\n",
    "#tablePair = teamTables(tables)\n",
    "\n",
    "# Due to an issue with the text scraping this function is required \n",
    "# It runs over the arrays and splits the player names from their positions\n",
    "def nameSplit(teamStats):\n",
    "    result=[]\n",
    "    for table in teamStats:\n",
    "        newtable = []\n",
    "        for row in table:\n",
    "            \n",
    "            if len(row)<1:\n",
    "                newtable.append(row)\n",
    "            else:\n",
    "                try: \n",
    "                    newtable.append([row[0][0], row[0][1]]+[i for sublist in row[1:len(row)] for i in sublist])\n",
    "                except IndexError:\n",
    "                    newtable.append([row[0][0], \"R\"]+[i for sublist in row[1:len(row)] for i in sublist])\n",
    "        result.append(newtable)\n",
    "    return result\n",
    "\n",
    "#team1 = nameSplit(tablePair[0])\n",
    "\n",
    "scoringHeaders = [\"Name\", \"Position\", \"Try\", \"Try Assist\", \"Conversion\", \"Penalty\", \"Drop Goal\", \"Points\"]\n",
    "attackingHeaders = [\"Name\", \"Position\", \"Blank\", \"Passes\", \"Runs\", \"Meters Run\", \"Clean Breaks\", \"Defenders Beaten\", \"Offloads\", \"Blank\"] \n",
    "defendingHeaders = [\"Name\", \"Position\", \"Turnovers Conceeded\", \"Tackles\", \"Missed Tackles\", \"Lineouts Won\"]\n",
    "disciplineHeaders = [\"Name\", \"Position\", \"Penalties\", \"Yellow Cards\", \"Red Cards\"]\n",
    "\n",
    "headers = [scoringHeaders, attackingHeaders, defendingHeaders, disciplineHeaders]\n",
    "\n",
    "# Function adds headers to \n",
    "def addHeaders(tableset):\n",
    "    for i, t in enumerate(tableset):\n",
    "        t[0] = headers[i]\n",
    "\n",
    "#addHeaders(team1)\n",
    "#addHeaders(team2)\n",
    "#pprint(team1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# Function takes one of our arrays of player stats and makes a dataframe\n",
    "def tableToDF(table):\n",
    "    df = pd.DataFrame(table)\n",
    "    df.columns = df.iloc[0]\n",
    "    #df.set_index('Name', inplace=True)\n",
    "    df.drop([0], axis=0, inplace =True)\n",
    "    return df\n",
    "\n",
    "# Function takes all our tables for a team, converts to DF and merge them on the name and position\n",
    "# Function also converts all numeric columns to numbers and drops some blank columns\n",
    "def tablesToDFs(tables):\n",
    "    dfs = []\n",
    "    for t in tables:\n",
    "        dfs.append(tableToDF(t))\n",
    "    df_final = reduce(lambda left,right: pd.merge(left,right, on=['Name', 'Position']), dfs)\n",
    "    cols = list(df_final.columns)\n",
    "    cols.remove('Name')\n",
    "    cols.remove('Position')\n",
    "    for col in cols:\n",
    "        df_final[col]=df_final[col].apply(pd.to_numeric, errors='coerce')\n",
    "    df_final.drop(['Blank'], axis=1, inplace=True)\n",
    "    return df_final\n",
    "\n",
    "#teamDF1 = tablesToDFs(team1)\n",
    "\n",
    "#addCols = testGame[0]\n",
    "#print(addCols)\n",
    "\n",
    "def homeTeamsData(teamDF):\n",
    "    teamDF[\"Team\"] = addCols[1]\n",
    "    teamDF[\"Opposition\"] = addCols[2]\n",
    "    teamDF[\"Points For\"] = addCols[3].split(\" \")[0]\n",
    "    teamDF[\"Points Against\"] = addCols[3].split(\" \")[2]\n",
    "    teamDF[\"Home/Away\"] = \"Home\"\n",
    "    teamDF[\"Date\"] = addCols[0]\n",
    "\n",
    "def awayTeamsData(teamDF):\n",
    "    teamDF[\"Team\"] = addCols[2]\n",
    "    teamDF[\"Opposition\"] = addCols[1]\n",
    "    teamDF[\"Points For\"] = addCols[3].split(\" \")[2]\n",
    "    teamDF[\"Points Against\"] = addCols[3].split(\" \")[0]\n",
    "    teamDF[\"Home/Away\"] = \"Away\"\n",
    "    teamDF[\"Date\"] = addCols[0]\n",
    "\n",
    "#homeTeamsData(teamDF1)\n",
    "\n",
    "#teamDF1.to_csv('testFile.csv')\n",
    "\n",
    "#print(teamDF1.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['20151011', 'ROM', 'ITALY', '22 - 32'], 'gameId=182008&league=164205'),\n",
      " (['20151004', 'IRE', 'ITALY', '16 - 9'], 'gameId=181996&league=164205'),\n",
      " (['20150926', 'ITALY', 'CAN', '23 - 18'], 'gameId=181984&league=164205'),\n",
      " (['20150919', 'FRA', 'ITALY', '32 - 10'], 'gameId=181972&league=164205'),\n",
      " (['20150905', 'WALES', 'ITALY', '23 - 19'], 'gameId=252323&league=252321'),\n",
      " (['20150829', 'SCOT', 'ITALY', '48 - 7'], 'gameId=263333&league=252321'),\n",
      " (['20150823', 'ITALY', 'SCOT', '12 - 16'], 'gameId=263325&league=248937'),\n",
      " (['20150321', 'ITALY', 'WALES', '20 - 61'], 'gameId=180691&league=180659'),\n",
      " (['20150315', 'ITALY', 'FRA', '0 - 29'], 'gameId=180690&league=180659'),\n",
      " (['20150228', 'SCOT', 'ITALY', '19 - 22'], 'gameId=180685&league=180659'),\n",
      " (['20150214', 'ENG', 'ITALY', '47 - 17'], 'gameId=180682&league=180659'),\n",
      " (['20150207', 'ITALY', 'IRE', '3 - 26'], 'gameId=180680&league=180659')]\n"
     ]
    }
   ],
   "source": [
    "pprint(full_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell takes all the above functions and puts them together to save CSVs of all the games a team has played in a given year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_reports = full_reports[1:]\n",
    "\n",
    "for m  in select_reports:\n",
    "    testPage = \"http://www.espn.co.uk/rugby/playerstats?\"+m[1]\n",
    "\n",
    "    browser = webdriver.Chrome(r\"C:\\Users\\Maurice\\Desktop\\Python\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "    pageSet = scrapePage(testPage)\n",
    "    \n",
    "    tables = gettables(pageSet)\n",
    "    tablePair = teamTables(tables)\n",
    "    \n",
    "    teamDFs = []\n",
    "    for t in tablePair:\n",
    "        team = nameSplit(t)\n",
    "        addHeaders(team)\n",
    "        teamDFs.append(tablesToDFs(team))\n",
    "    \n",
    "    addCols = m[0]\n",
    "    homeTeamsData(teamDFs[0])\n",
    "    awayTeamsData(teamDFs[1])\n",
    "    \n",
    "    result = pd.concat(teamDFs)\n",
    "    result.to_csv(addCols[0]+\" \"+addCols[1]+\"-\"+addCols[2]+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
